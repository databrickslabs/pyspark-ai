{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Spark LLM Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/amanda.liu/Documents/Databricks/spark-llm/examples', '/Users/amanda.liu/anaconda3/envs/llm-spark/lib/python311.zip', '/Users/amanda.liu/anaconda3/envs/llm-spark/lib/python3.11', '/Users/amanda.liu/anaconda3/envs/llm-spark/lib/python3.11/lib-dynload', '', '/Users/amanda.liu/anaconda3/envs/llm-spark/lib/python3.11/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spark_llm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspark_llm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkLLMAssistant\n\u001b[1;32m      4\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# using gpt-4 can achieve better results\u001b[39;00m\n\u001b[1;32m      5\u001b[0m assistant\u001b[38;5;241m=\u001b[39mSparkLLMAssistant(llm\u001b[38;5;241m=\u001b[39mllm, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spark_llm'"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from spark_llm import SparkLLMAssistant\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-4') # using gpt-4 can achieve better results\n",
    "assistant=SparkLLMAssistant(llm=llm, verbose=True)\n",
    "assistant.activate() # active partial functions for Spark DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Example 1: Auto sales by brand in US 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Search and ingest web content into a DataFrame\n",
    "auto_df = assistant.create_df(\"2022 USA national auto sales by brand\")\n",
    "auto_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "auto_df.llm_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Apply transforms to a Dataframe\n",
    "auto_top_growth_df=auto_df.llm_transform(\"top brand with the highest growth\")\n",
    "auto_top_growth_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Explain what a DataFrame is retrieving.\n",
    "auto_top_growth_df.llm_explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Example 2: USA Presidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# You can also specify the expected columns for the ingestion.\n",
    "df=assistant.create_df(\"USA presidents\", [\"president\", \"vice_president\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "presidents_who_were_vp = df.llm_transform(\"presidents who were also vice presidents\")\n",
    "presidents_who_were_vp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "presidents_who_were_vp.llm_explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Example 3: Top 10 tech companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Search and ingest web content into a DataFrame\n",
    "company_df=assistant.create_df(\"Top 10 tech companies by market cap\", ['company', 'cap', 'country'])\n",
    "company_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "us_company_df=company_df.llm_transform(\"companies in USA\")\n",
    "us_company_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "us_company_df.llm_explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "us_company_df.llm_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Example 4: Ingestion from a URL\n",
    "Instead of searching for the web page, you can also ask the assistant to ingest from a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "assistant.create_df('https://time.com/6235186/best-albums-2022/').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Test generation\n",
    "You can ask the assistant to generate test code for a given dataframe transformation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "def remove_non_word_characters(col):\n",
    "    return F.regexp_replace(col, \"[^\\\\w\\\\s]+\", \"\")\n",
    "\n",
    "assistant.test_llm(remove_non_word_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "import unittest\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "def remove_non_word_characters(df, column_name):\n",
    "    \\\"\"\"\n",
    "    This function takes a dataframe and a column name as input, and returns a dataframe\n",
    "    with non-word characters removed from the specified column.\n",
    "    \\\"\"\"\n",
    "    return df.withColumn(column_name, regexp_replace(col(column_name), r'\\W+', ''))\n",
    "\n",
    "\n",
    "class TestRemoveNonWordCharacters(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.spark = SparkSession.builder \\\n",
    "            .master(\"local[1]\") \\\n",
    "            .appName(\"TestRemoveNonWordCharacters\") \\\n",
    "            .getOrCreate()\n",
    "        schema = StructType([\n",
    "            StructField(\"text\", StringType(), True)\n",
    "        ])\n",
    "        self.input_data = [\n",
    "            (\"Hello, World!\",),\n",
    "            (\"I'm a test-case.\",),\n",
    "            (\"123,456,789.00\",),\n",
    "        ]\n",
    "        self.expected_data = [\n",
    "            (\"HelloWorld\",),\n",
    "            (\"Imatestcase\",),\n",
    "            (\"12345678900\",),\n",
    "        ]\n",
    "\n",
    "    def test_remove_non_word_characters(self):\n",
    "        input_df = self.spark.createDataFrame(self.input_data, schema=schema)\n",
    "        expected_df = self.spark.createDataFrame(self.expected_data, schema=schema)\n",
    "\n",
    "        result_df = remove_non_word_characters(input_df, \"text\")\n",
    "\n",
    "        self.assertTrue(result_df.subtract(expected_df).count() == 0 and\n",
    "                        expected_df.subtract(result_df).count() == 0,\n",
    "                        msg=\"The function did not remove non-word characters correctly.\")\n",
    "\n",
    "    def tearDown(self):\n",
    "        self.spark.stop()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
    "        result = \"OK\"\n",
    "    except Exception as e: \n",
    "        result = f\"Error\"\n",
    "\"\"\"\n",
    "    \n",
    "locals_ = {}\n",
    "exec(code, {}, locals_)\n",
    "\n",
    "print(f\"\\nResult: {locals_['__name__']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
